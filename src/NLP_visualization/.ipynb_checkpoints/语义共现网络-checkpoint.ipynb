{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import jieba, codecs, math\n",
    "import jieba.posseg as pseg\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelationExtractor:\n",
    "\n",
    "    def __init__(self, fpStopWords, fpNameDicts, fpAliasNames):\n",
    "        # 人名词典\n",
    "        self.name_dicts = [line.strip().split(' ')[0] for line in open(fpNameDicts,'rt',encoding='utf-8').readlines()]\n",
    "        # 停止词表\n",
    "        self.stop_words = [line.strip() for line in open(fpStopWords,'rt',encoding='utf-8').readlines()]\n",
    "        # 别名词典\n",
    "        self.alias_names = dict([(line.split(',')[0].strip(), line.split(',')[1].strip()) for line in open(fpAliasNames,'rt',encoding='utf-8').readlines()])\n",
    "        # 加载词典\n",
    "        jieba.load_userdict(fpNameDicts)\n",
    "\n",
    "    # 提取指定小说文本中的人物关系\n",
    "    def extract(self, fpText):\n",
    "        # 人物关系\n",
    "        relationships = {}\n",
    "        # 人名频次\n",
    "        name_frequency = {}\n",
    "        # 每个段落中的人名\n",
    "        name_in_paragraph = []\n",
    "\n",
    "        # 读取小说文本，统计人名出现的频次，以及每个段落中出现的人名\n",
    "        with codecs.open(fpText, \"r\", \"utf8\") as f:\n",
    "            for line in f.readlines():\n",
    "                poss = pseg.cut(line)\n",
    "                name_in_paragraph.append([])\n",
    "                for w in poss:\n",
    "                    if w.flag != \"nr\" or len(w.word) < 2:\n",
    "                        continue\n",
    "                    if (w.word in self.stop_words):\n",
    "                        continue\n",
    "                    if (not w.word in self.name_dicts and w.word != '半泽'):\n",
    "                        continue\n",
    "                    # 规范化人物姓名，例：半泽->半泽直树，大和田->大和田晓\n",
    "                    word = w.word\n",
    "                    if (self.alias_names.get(word)):\n",
    "                        word = self.alias_names.get(word)  \n",
    "                    name_in_paragraph[-1].append(word)\n",
    "                    if name_frequency.get(word) is None:\n",
    "                        name_frequency[word] = 0\n",
    "                        relationships[word] = {}\n",
    "                    name_frequency[word] += 1\n",
    "\n",
    "        # 基于共现组织人物关系\n",
    "        for paragraph in name_in_paragraph:\n",
    "            for name1 in paragraph:\n",
    "                for name2 in paragraph:\n",
    "                    if name1 == name2:\n",
    "                        continue\n",
    "                    if relationships[name1].get(name2) is None:\n",
    "                        relationships[name1][name2] = 1\n",
    "                    else:\n",
    "                        relationships[name1][name2] += 1 \n",
    "        \n",
    "        # 返回节点和边\n",
    "        return name_frequency, relationships\n",
    "\n",
    "    # 输出Gephi格式的节点和边信息\n",
    "    def exportGephi(self, nodes, relationships):\n",
    "        # 输出节点\n",
    "        with codecs.open(\"./node.txt\", \"w\", \"gbk\") as f:\n",
    "            f.write(\"Id Label Weight\\r\\n\")\n",
    "            for name, freq in nodes.items():\n",
    "                f.write(name + \" \" + name + \" \" + str(freq) + \"\\r\\n\")\n",
    "\n",
    "        # 输出边\n",
    "        with codecs.open(\"./edge.txt\", \"w\", \"gbk\") as f:\n",
    "            f.write(\"Source Target Weight\\r\\n\")\n",
    "            for name, edges in relationships.items():\n",
    "                for v, w in edges.items():\n",
    "                    if w > 0:\n",
    "                        f.write(name + \" \" + v + \" \" + str(w) + \"\\r\\n\")   \n",
    "\n",
    "    # 使用ECharts对人物关系进行渲染\n",
    "    def exportECharts(self, nodes, relationships):\n",
    "        # 总频次，用于数据的归一化\n",
    "        total = sum(list(map(lambda x:x[1], nodes.items())))\n",
    "\n",
    "        # 输出节点\n",
    "        nodes_data = []\n",
    "        for name, freq in nodes.items():\n",
    "            nodes_data.append(opts.GraphNode(\n",
    "                name = name, \n",
    "                symbol_size = round(freq / total * 100, 2), \n",
    "                value = freq,\n",
    "            )),\n",
    "\n",
    "        # 输出边\n",
    "        links_data = []\n",
    "        for name, edges in relationships.items():\n",
    "                for v, w in edges.items():\n",
    "                    if w > 0:\n",
    "                        links_data.append(opts.GraphLink(\n",
    "                            source = v, \n",
    "                            target = w, \n",
    "                            value = w\n",
    "                        ))\n",
    "\n",
    "        # 绘制Graph\n",
    "        c = (\n",
    "            Graph()\n",
    "            .add(\n",
    "                \"\",\n",
    "                nodes_data,\n",
    "                links_data,\n",
    "                gravity = 0.2,\n",
    "                repulsion = 8000,\n",
    "                is_draggable = True,\n",
    "                symbol = 'circle',\n",
    "                linestyle_opts = opts.LineStyleOpts(\n",
    "                    curve = 0.3, \n",
    "                    width = 0.5, \n",
    "                    opacity = 0.7\n",
    "                ),\n",
    "                edge_label = opts.LabelOpts(\n",
    "                    is_show = False, \n",
    "                    position = \"middle\", \n",
    "                    formatter = \"{b}->{c}\"\n",
    "                ),\n",
    "            )\n",
    "            .set_global_opts(\n",
    "                title_opts = opts.TitleOpts(title=\"小说人物关系抽取\")\n",
    "            )\n",
    "            .render(\"./小说人物关系抽取.html\")\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = RelationExtractor('../../Resources/stopwords/baidu_stopwords.txt',\n",
    "    './人名词典.txt',\n",
    "    './别名词典.txt'\n",
    ")\n",
    "nodes, relationships = extractor.extract('./鹿鼎记.txt')\n",
    "extractor.exportGephi(nodes, relationships)\n",
    "extractor.exportECharts(nodes, relationships)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NLP_DEMO]",
   "language": "python",
   "name": "conda-env-NLP_DEMO-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
